# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºæ•°æ®åŠ è½½æ¨¡å—

ä» mono_finding ç›®å½•åŠ è½½å·²æŠ“å–çš„ JSON æ ·æœ¬æ•°æ®ç”¨äºæ¼”ç¤ºã€‚
"""

import json
import os
from typing import List, Dict


class DemoDataLoader:
    """æ¼”ç¤ºæ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, data_dir: str = None):
        if data_dir is None:
            # è‡ªåŠ¨å®šä½ mono_finding ç›®å½•
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(os.path.dirname(current_dir))
            data_dir = os.path.join(project_root, 'mono_finding')
        
        self.data_dir = data_dir
        self._hot_search_data = None
        self._channel_data = None
    
    def load_hot_search_list(self) -> List[Dict]:
        """
        åŠ è½½çƒ­æœæ¦œæ ·æœ¬æ•°æ®
        
        ä» b.json æˆ– d.json åŠ è½½ï¼ˆçƒ­æœæ¦œAPIå“åº”ï¼‰
        """
        if self._hot_search_data:
            return self._hot_search_data
        
        # ä¼˜å…ˆåŠ è½½ b.json
        for filename in ['b.json', 'd.json']:
            filepath = os.path.join(self.data_dir, filename)
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    self._hot_search_data = self._parse_hot_search(data)
                    print(f"[Demo] ä» {filename} åŠ è½½äº† {len(self._hot_search_data)} æ¡çƒ­æœ")
                    return self._hot_search_data
                    
                except Exception as e:
                    print(f"[Demo] åŠ è½½ {filename} å¤±è´¥: {e}")
                    continue
        
        return []
    
    def _parse_hot_search(self, data: dict) -> List[Dict]:
        """è§£æçƒ­æœAPIå“åº”"""
        hot_list = []
        
        # è§£æ word_list
        word_list = data.get('data', {}).get('word_list', [])
        for item in word_list:
            position = item.get('position', 0)
            
            label = item.get('label', 0)
            tag = self._parse_label(label)
            
            cover_url = ""
            word_cover = item.get('word_cover', {})
            if word_cover and word_cover.get('url_list'):
                cover_url = word_cover['url_list'][0]
            
            hot_list.append({
                'position': position,
                'word': item.get('word', ''),
                'hot_value': item.get('hot_value', 0),
                'view_count': item.get('view_count', 0),
                'video_count': item.get('video_count', 0),
                'sentence_id': item.get('sentence_id', ''),
                'tag': tag,
                'cover_url': cover_url,
                'url': f"https://www.douyin.com/hot/{item.get('sentence_id', '')}"
            })
        
        # è§£æ trending_listï¼ˆå®æ—¶ä¸Šå‡ï¼‰
        trending_list = data.get('data', {}).get('trending_list', [])
        for item in trending_list:
            cover_url = ""
            word_cover = item.get('word_cover', {})
            if word_cover and word_cover.get('url_list'):
                cover_url = word_cover['url_list'][0]
            
            hot_list.append({
                'position': 0,
                'word': item.get('word', ''),
                'hot_value': item.get('hot_value', 0),
                'view_count': 0,
                'video_count': item.get('video_count', 0),
                'sentence_id': item.get('sentence_id', ''),
                'tag': 'ä¸Šå‡',
                'cover_url': cover_url,
                'url': f"https://www.douyin.com/hot/{item.get('sentence_id', '')}"
            })
        
        return hot_list
    
    def _parse_label(self, label: int) -> str:
        """è§£ææ ‡ç­¾ç±»å‹"""
        label_map = {
            0: '',
            1: 'æ–°',
            3: 'çƒ­',
            8: 'ç‹¬å®¶',
            16: 'è¾Ÿè°£',
            17: 'çƒ­èˆ',
        }
        return label_map.get(label, '')
    
    def load_channel_hotspot(self) -> List[Dict]:
        """
        åŠ è½½é¢‘é“çƒ­ç‚¹æ ·æœ¬æ•°æ®
        
        ä» a.json, c.json æˆ– e.json åŠ è½½
        """
        if self._channel_data:
            return self._channel_data
        
        for filename in ['a.json', 'c.json', 'e.json']:
            filepath = os.path.join(self.data_dir, filename)
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    self._channel_data = self._parse_channel(data)
                    print(f"[Demo] ä» {filename} åŠ è½½äº† {len(self._channel_data)} ä¸ªçƒ­ç‚¹è§†é¢‘")
                    return self._channel_data
                    
                except Exception as e:
                    print(f"[Demo] åŠ è½½ {filename} å¤±è´¥: {e}")
                    continue
        
        return []
    
    def _parse_channel(self, data: dict) -> List[Dict]:
        """è§£æé¢‘é“çƒ­ç‚¹å“åº”"""
        videos = []
        
        aweme_list = data.get('aweme_list', [])
        for item in aweme_list:
            author = item.get('author', {})
            statistics = item.get('statistics', {})
            video = item.get('video', {})
            
            cover_url = ""
            cover = video.get('cover', {})
            if cover and cover.get('url_list'):
                cover_url = cover['url_list'][0]
            
            avatar_url = ""
            avatar = author.get('avatar_thumb', {})
            if avatar and avatar.get('url_list'):
                avatar_url = avatar['url_list'][0]
            
            videos.append({
                'aweme_id': item.get('aweme_id', ''),
                'desc': item.get('desc', ''),
                'caption': item.get('caption', ''),
                'create_time': item.get('create_time', 0),
                'duration': item.get('duration', 0),
                'author': {
                    'uid': author.get('uid', ''),
                    'nickname': author.get('nickname', ''),
                    'sec_uid': author.get('sec_uid', ''),
                    'avatar_url': avatar_url,
                },
                'statistics': {
                    'digg_count': statistics.get('digg_count', 0),
                    'comment_count': statistics.get('comment_count', 0),
                    'share_count': statistics.get('share_count', 0),
                    'collect_count': statistics.get('collect_count', 0),
                },
                'cover_url': cover_url,
                'url': f"https://www.douyin.com/video/{item.get('aweme_id', '')}"
            })
        
        return videos


# å•ä¾‹
_demo_loader_instance = None

def get_demo_loader() -> DemoDataLoader:
    """è·å–æ¼”ç¤ºæ•°æ®åŠ è½½å™¨å•ä¾‹"""
    global _demo_loader_instance
    if _demo_loader_instance is None:
        _demo_loader_instance = DemoDataLoader()
    return _demo_loader_instance


if __name__ == '__main__':
    loader = DemoDataLoader()
    
    print("=== åŠ è½½çƒ­æœæ¦œæ•°æ® ===")
    hot_list = loader.load_hot_search_list()
    for item in hot_list[:10]:
        print(f"#{item['position']} [{item['tag']}] {item['word']} - {item['hot_value']:,}")
    
    print("\n=== åŠ è½½é¢‘é“çƒ­ç‚¹æ•°æ® ===")
    videos = loader.load_channel_hotspot()
    for v in videos[:5]:
        print(f"@{v['author']['nickname']}: {v['desc'][:30]}...")
        print(f"  ğŸ‘{v['statistics']['digg_count']:,} ğŸ’¬{v['statistics']['comment_count']:,}")
